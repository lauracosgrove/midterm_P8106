---
title: "Predicting County-Level Heart Disease Mortality in the United States"
author: "Charlotte Abrams, Laura Cosgrove, Alyssa Vanderbeek"
date: "7 April 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(earth)
library(patchwork)
```


## Introduction
### Background

Heart disease remains one of the leading causes of death in adults in the US. Understanding risk factors for diseases of this kind is an important task in working towards reducing the number of lives lost. There is obvious benefit in doing this at an individual level, examining personal lifestyle, genetic profile, and family history. But there may be important environmental components that have predictive value in assessing risk for heart disease mortality. We examine economic, health, and demographic data for thousands of counties across the US. This data is synthesized from several sources, including the USDA Economic Research Service, Bureau of Labor Statistics, US Census, Behavioral Risk Factor Surveillance System, the CDC, and others. Our goal in this project is to most effectively predict the county-level heart disease mortality rate per 100,000 persons. We build 6 predictive models (stepwise linear regression, Lasso, Ridge, PCR, GAM, and MARS), and compare them on their predictive capacity quantified by the root mean squared error (RMSE).


### Exploratory Data Analysis (Laura)


```{r, echo = FALSE, fig.width = 10}
heart <- read_rds("./data/full_processed_data.Rdata")

##Factor Variables
heart %>% 
  ggplot(aes(x = heart_disease_mortality_per_100k, y = metro, height=..density..)) +
  ggjoy::geom_joy(scale = 0.85)

heart %>% 
  ggplot(aes(x = heart_disease_mortality_per_100k, y = metro_adjacency, fill = urban_influence, height=..density..)) +
  ggjoy::geom_joy(scale = 0.85, alpha = 0.3) 

```

The global mean of heart disease mortality per 100,000 residents is `r round(mean(heart$heart_disease_mortality_per_100k), 2)`, with standard deviation `r round(sd(heart$heart_disease_mortality_per_100k), 2)`. It is approximately normally distributed.

The distribution of heart disease mortality differs among levels of factor variables, but is broadly similar. Many of the factor variables included in this dataset contain similar information at different levels of interaction, or hierarchical division. For example, as shown in the second density plot, metro adjacency (a variable created from the original RUCCS hierarchical coding) is a less fine-grained look at urban influence, and urban influence may then function as an interaction between metro adjacency and population (in our dataset, `pure_population` is also created from the original RUCCS hierarchical coding in pre-processing) To get at these different specificities and as a "proxy" for including pseudo-interaction terms, we include all these factor variables for our initial model fit. 

### Correlations and Collinearity
```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 10}

##Functions
substring = function (x) {str_sub(x, start = -25)}

str_remove_hlth <- function(x) {
  str_remove(x, pattern = "health__")
}

str_remove_econ <- function(x) {
  str_remove(x, pattern = "econ__")
}

str_remove_demo <- function(x) {
  str_remove(x, pattern = "demo__")
}

str_remove_pct <- function(x) {
  str_remove(x, pattern = "pct_")
}

#Within category correlation
par(mfrow=c(1,3))

heart %>% 
  select_if(is.numeric) %>% 
  select(starts_with("econ")) %>% 
  rename_all(str_remove_econ) %>% 
  rename_all(str_remove_pct) %>% 
  rename_all(substring) %>% 
  drop_na() %>% 
  cor() %>% 
  corrplot::corrplot(method = "ellipse")

heart %>% 
  select_if(is.numeric) %>% 
  select(starts_with("demo")) %>% 
  rename_all(str_remove_demo) %>% 
  rename_all(str_remove_pct) %>% 
  rename_all(substring) %>% 
  drop_na() %>% 
  cor() %>% 
  corrplot::corrplot(method = "ellipse")

heart %>% 
  select_if(is.numeric) %>% 
  select(starts_with("health")) %>% 
  rename_all(str_remove_hlth) %>% 
  rename_all(str_remove_pct) %>% 
  rename_all(substring) %>% 
  drop_na() %>% 
  cor() %>% 
  corrplot::corrplot(method = "ellipse")

cor_matrix <- heart %>% 
  select_if(is.numeric) %>% 
  drop_na() %>% 
  cor()

cor_tibble = as_tibble(cor_matrix)

## Between category correlation
econ <- tibble(variable = names(cor_tibble),
                  econ__pct_civilian_labor = cor_tibble$econ__pct_civilian_labor,
       econ__pct_unemployment = cor_tibble$econ__pct_unemployment,
       econ__pct_uninsured_adults = cor_tibble$econ__pct_uninsured_adults,
       econ__pct_uninsured_children = cor_tibble$econ__pct_uninsured_children) %>% 
  filter(variable != "heart_disease_mortality_per_100k",
         !str_detect(variable, "econ")) %>% 
  arrange(variable) %>% 
  mutate(flag = case_when(abs(econ__pct_civilian_labor) > 0.6 ~ "flag",
                        abs(econ__pct_unemployment) > 0.6 ~ "flag",
                        abs(econ__pct_uninsured_adults) > 0.6 ~ "flag",
                        abs(econ__pct_uninsured_children) > 0.6 ~ "flag")) %>% 
  filter(flag == "flag") %>% 
  select(-flag)

health <- tibble(variable = names(cor_tibble),
                  health__air_pollution_particulate_matter = cor_tibble$health__air_pollution_particulate_matter,
       health__motor_vehicle_crash_deaths_per_100k = cor_tibble$health__motor_vehicle_crash_deaths_per_100k,
       health__pct_adult_obesity = cor_tibble$health__pct_adult_obesity,
       health__pct_adult_smoking = cor_tibble$health__pct_adult_smoking,
      health__pct_diabetes = cor_tibble$health__pct_diabetes,
       health__pct_low_birthweight = cor_tibble$health__pct_low_birthweight,
       health__pct_physical_inacticity = cor_tibble$health__pct_physical_inacticity,
       health__pop_per_dentist = cor_tibble$health__pop_per_dentist,
      health__pop_per_primary_care_physician = cor_tibble$health__pop_per_primary_care_physician) %>% 
  filter(variable != "heart_disease_mortality_per_100k",
         !str_detect(variable, "health")) %>% 
  arrange(variable) %>% 
  mutate(flag = case_when(abs(health__air_pollution_particulate_matter) > 0.6 ~ "flag",
                        abs(health__motor_vehicle_crash_deaths_per_100k) > 0.6 ~ "flag",
                        abs(health__pct_adult_obesity) > 0.6 ~ "flag",
                        abs(health__pct_adult_smoking) > 0.6 ~ "flag",
                      abs(health__pct_diabetes) > 0.6 ~ "flag",
                      abs(health__pct_low_birthweight) > 0.6 ~ "flag",
                      abs(health__pct_physical_inacticity) > 0.6 ~ "flag",
                      abs(health__pop_per_dentist) > 0.6 ~ "flag",
                      abs(health__pop_per_primary_care_physician) > 0.6 ~ "flag")) %>% 
  filter(flag == "flag")

econ <- econ %>% 
  gather(key = with, value = correlation, starts_with("econ")) %>% 
  filter(abs(correlation) > 0.6)

health <- health %>% 
  select(-flag) %>% 
  gather(key = with, value = correlation, starts_with("health")) %>% 
  group_by(variable) %>% 
  filter(abs(correlation) > 0.6)

multicollinearity <- full_join(econ, health)

multicollinearity %>% 
  knitr::kable(format = "latex", caption = "Highly Correlated Predictors Between Categories", digits = 2)

##Correlation with outcome
heart_attacks_cor = tibble(variable = names(cor_tibble),
                     correlation = cor_tibble$heart_disease_mortality_per_100k)

heart_attacks_cor %>% 
    arrange(desc(abs(correlation))) %>% 
    knitr::kable(format = "latex", caption = "Correlation with Outcome", digits = 2)

```

We investigated possible multicollinearity both between and within categories.

Health statistics related to healthy behaviors are highly intercorrelated: obesity, smoking, diabetes, low birthweight babies, excessive drinking, and physical inactivity. Less so are more environment- or "acts of God"-related health behaviors: particulate matter, homocides, motor vehicle crashes, and rates of dentists and doctors (though the last two are highly correlated).

For demography, there's some categorical variables masquerading as separate predictors, leading to high intercorrelation within those categories: percentages of residents who are a given race accounts for 5 variables; age-related bins (less than 18, greater than 65) account for 2 variables; birth and death rate; and percentages of residents who complete a given level of education account for 4 variables.

For economics, unsurprisingly, the percent of adults and the percent of children without health insurance  are highly correlated, as well as percent civilian labor and unemployment rate.

Between categories, education-related variables are highly correlated with % civilian labor, % uninsured adults, and % physical inactivity.

Predictors strongly associated with heart disease mortality are % physical inactivity, % diabetes, % adult obesity, education-related variables, % low birthweight, and overall death rate per 1,000. Many of the variables most strongly-associated with the outcome are associated with one another.

## Data Methods

**note: transform test data by centering and scaling with TRAINING means and standard deviations. Does predict do this automatically when using `preProcess` in caret?
-- done

can consider imputation: say 10%, one possible solution. use the training set to build. Look at the preProcess function, can use knn. 
-- done. Still dropped two columns because they had 90\% missing data; imputation not reliable

Check/detect near-zero variance predictors: to decrease computational time and complexity.
-- done. A few of the categories for urban influence came back as having near-zero variance. These were examined as dummy variables; 2000 rows divided across 12 levels means that these are likely to be "rare". We determined that we ought to leave them in the model since they are part of the larger variable "urban_influence".

## Linear Models

```{r, echo=FALSE}
train <- read_rds("./data/train_imputed.Rdata") 
x <- model.matrix(heart_disease_mortality_per_100k ~ ., data = train)[,-1]
y <- train$heart_disease_mortality_per_100k

test_df = readr::read_rds("data/test_imputed.Rdata")
test_outcome = test_df$heart_disease_mortality_per_100k
test = model.matrix(heart_disease_mortality_per_100k ~ ., data = test_df)

# load the model fits from previous runs
lm_fit <- readRDS("lm_step_imputed.rds")
ridge_fit <- readRDS("ridge.rds")
mars_fit <- readRDS("mars2.rds")
gam_fit <- readRDS("gam_fit_imputed.rds")
lasso_fit <- readRDS("lasso_imputed.rds")
pcr_fit <- readRDS("pcr_imputed.rds")
```


### Stepwise Selection (Alyssa)

We first fit a stepwise linear regression model. 

### Lasso (Charlotte)

### Ridge (Laura)

### PCR (Charlotte)

## Nonlinear Models

### GAM (Alyssa)

### MARS (Laura)

Note that we chose the most parsimonious model.


## Model Comparison 

### Training RMSE

```{r, echo = FALSE}
set.seed(2)

# resample each model to compare 
res <- resamples(list(
  Stepwise = lm_fit,
  Ridge = ridge_fit,
  Lasso = lasso_fit,
  PCR = pcr_fit,
  GAM = gam_fit,
  MARS = mars_fit
  ))

# plot RMSE ad CI for each model to compare predictive ability
ggplot(res, metric = "RMSE") +
  theme_minimal() +
  labs(title = "Resampled Training RMSE")
```

The more flexible model 

### Test RMSE (Alyssa)

```{r, echo = FALSE}
pred_lm = predict(lm_fit, newdata = test)
pred_ridge = predict(ridge_fit, test)
pred_lasso = predict(lasso_fit, test)
pred_pcr = predict(pcr_fit, test)
pred_gam = predict(gam_fit, test)
pred_mars = predict(mars_fit, test)

data.frame(train_rmse = summary(res)$statistics$RMSE[,4],
           test_rmse = c(sqrt(mean((pred_lm - test_outcome)^2)),
                         sqrt(mean((pred_ridge - test_outcome)^2)),
                         sqrt(mean((pred_lasso - test_outcome)^2)),
                         sqrt(mean((pred_pcr - test_outcome)^2)),
                         sqrt(mean((pred_gam - test_outcome)^2)),
                         sqrt(mean((pred_mars - test_outcome)^2)))) %>%
  `colnames<-`(c("Train RMSE", "Test RMSE")) %>%
  knitr::kable(caption = "Predictive RMSE on training and test data")
```


Table 1 presents the RMSE of the predicted heart disease mortality rate for all models on both the training and testing datasets. Although GAM appeared to have the lowest RMSE when using the training data, MARS has similar performance to the GAM model in the test data. 


### Interpretations (Laura)

_Coefficient Shrinkage: Lasso and Ridge_

```{r, echo = FALSE, warning = FALSE}

##Coefficient Shrinkage

### Ridge 
best_lambda_ridge = ridge_fit$bestTune$lambda 

ridge_cv_glmnet <- glmnet::cv.glmnet(x, y, 
                      alpha = 0, 
                      lambda = exp(seq(-2, 10, length = 200)), 
                      type.measure = "mse")

### Lasso 
best_lambda_lasso = lasso_fit$bestTune$lambda 

predict(lasso_fit$finalModel, s = best_lambda_lasso, type = "coefficients") %>% 
  dim() #no shrinkage

lasso_cv_glmnet <- glmnet::cv.glmnet(x, y, 
                      alpha = 1, 
                      lambda = exp(seq(-2, 4, length = 200)), 
                      type.measure = "mse")

plotmo::plot_glmnet(ridge_cv_glmnet$glmnet.fit, xvar = "lambda", label = 8) +
abline(v = log(best_lambda_ridge), col = "blue") + title(sub="CV-selected lambda in blue", xlab="Ridge")

plotmo::plot_glmnet(lasso_cv_glmnet$glmnet.fit, xvar = "lambda", label = 8) +
abline(v = log(best_lambda_lasso), col = "blue") + title(sub="CV-selected lambda in blue", xlab = "Lasso")
#could suggest selection of a more parsimonious model: lambda = exp(0)

#### Some of the most "important" coefficients
predict(ridge_fit$finalModel, s = best_lambda_ridge, type ="coefficients") %>% 
  broom::tidy() %>% 
  arrange(desc(abs(value))) %>% 
  top_n(10) %>% 
  knitr::kable(format = "latex", caption = "Top Absolute-Values Coefficients, Ridge")

predict(lasso_fit$finalModel, s = best_lambda_lasso, type ="coefficients") %>% 
  broom::tidy() %>% 
  arrange(desc(abs(value))) %>% 
  top_n(10) %>% 
  knitr::kable(format = "latex", caption = "Top Absolute-Valued Coefficients, Lasso")
```

For better visualization, a `glmnet` model was fit and the lambda value selected by `caret` was plotted. 

Overall, this modeling problem was perhaps not the best fit for lasso and ridge. Neither of the methods shrunk many coefficients in such a way that completely removed them from the model and improved the RMSE. The best visualization of the effect of shrinkage can be seen in the ridge coefficient plot, where it can be seen that the vast majority of coefficients shrunk equally. Lasso's more stringent shrinking power did not improve MSE for this problem.

If lasso and ridge were more appropriate for the problem, parameter selection might have been more obvious. As it is, as shown below, the standard error of the mean cross-validated error is quite wide.

```{r, echo = FALSE}
##MSE 
###Ridge
ridge_cv_table <- tibble(lambda_values = ridge_cv_glmnet$lambda, mse = ridge_cv_glmnet$cvm, mse_upper = ridge_cv_glmnet$cvup, mse_lower = ridge_cv_glmnet$cvlo)

ridge_cv_table_best <- ridge_cv_table %>% 
  arrange(mse) %>% 
  slice(which.min(abs(lambda_values - best_lambda_ridge)))

ridge_mse_plot <- ridge_cv_table %>% 
  filter(lambda_values %in% exp(seq(-2, 5, length = 200))) %>% 
  ggplot(aes(x = log(lambda_values), y = mse)) +
  geom_point() +
  geom_point(aes(x = log(best_lambda_ridge), y = ridge_cv_table_best$mse), color = "red") +
  geom_ribbon(aes(ymin = mse_lower, ymax = mse_upper), alpha = 0.3) + 
  labs(title = "Ridge Parameter Selection") +
  annotate("text", x = 0.5 + log(best_lambda_ridge), y = 1.05*ridge_cv_table_best$mse, label = "Lambda chosen by caret", color = "red") + 
  theme_minimal()

###Lasso
lasso_cv_table <- tibble(lambda_values = lasso_cv_glmnet$lambda, mse = lasso_cv_glmnet$cvm, mse_upper = lasso_cv_glmnet$cvup, mse_lower = lasso_cv_glmnet$cvlo)

lasso_cv_table_best <- lasso_cv_table %>% 
  arrange(mse) %>% 
  slice(which.min(abs(lambda_values - best_lambda_lasso)))

lasso_mse_plot <- lasso_cv_table %>% 
  filter(lambda_values %in% exp(seq(-2, 0, length = 200))) %>% 
  ggplot(aes(x = log(lambda_values), y = mse)) +
  geom_point() +
  geom_point(aes(x = log(best_lambda_lasso), y = lasso_cv_table_best$mse), color = "red") +
  geom_ribbon(aes(ymin = mse_lower, ymax = mse_upper), alpha = 0.3) +
  labs(title = "Lasso Parameter Selection") + 
  theme_minimal()
library(patchwork)

ridge_mse_plot + lasso_mse_plot
```

_Investigation of MARS_

The minimum generalized cross-validation error was achieved for a total of 25 features, including a two-way interaction term. Variable importance is assessed by tracking GCV for each predictor and accumulating the reduction in GCV when each predictorâ€™s feature is added to the model -- the total reduction is used as the measure of variable importance. If a predictor was never used in any MARS basis function, it has an importance value of zero; 18 predictors were used in a MARS basis function.

MARS retained interactions between many sets of health-related variables, which one might expect given collinearity (and relatedness) between the within-category variable sets. Interaction terms were also present across categories.

```{r, echo = FALSE, fig.width = 10}
vip::vip(mars_fit, num_features = 18, bar = FALSE, value = "gcv") + ggtitle("GCV")

str_remove_hlth <- function(x) {
  str_remove(x, pattern = "health__")
}

str_remove_econ <- function(x) {
  str_remove(x, pattern = "econ__")
}

str_remove_demo <- function(x) {
  str_remove(x, pattern = "demo__")
}

coef(mars_fit$finalModel) %>%
  broom::tidy() %>% 
  mutate(names = str_remove_hlth(names)) %>% 
  mutate(names = str_remove_hlth(names)) %>% 
  mutate(names = str_remove_econ(names)) %>% 
  mutate(names = str_remove_econ(names)) %>% 
  mutate(names = str_remove_demo(names)) %>% 
  mutate(names = str_remove_demo(names)) #%>% #repeated bc appears twice
 # knitr::kable(format = "latex")# %>% 
  #kableExtra::kable_styling(latex_options = "scale_down") 

p1 <- pdp::partial(mars_fit, pred.var = c("health__pct_physical_inacticity"), grid.resolution = 10) %>% autoplot()
p2 <- pdp::partial(mars_fit, pred.var = c("demo__pct_aged_65_years_and_older"), grid.resolution = 10) %>% autoplot()
p3 <- pdp::partial(mars_fit, pred.var = c("health__pct_diabetes"), grid.resolution = 10) %>% autoplot()
p4 <- pdp::partial(mars_fit, pred.var = c("health__pop_per_dentist"), grid.resolution = 10) %>% autoplot()

p5 <- pdp::partial(mars_fit, pred.var = c("health__pct_physical_inacticity", "demo__pct_aged_65_years_and_older"), grid.resolution = 10) %>%  pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, colorkey = TRUE, screen = list(z = -20, x = -60))
p6 <- pdp::partial(mars_fit, pred.var = c("health__pct_diabetes", "demo__pct_aged_65_years_and_older"), grid.resolution = 10) %>%  pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, colorkey = TRUE, screen = list(z = -20, x = -60))
p7 <- pdp::partial(mars_fit, pred.var = c("health__pct_diabetes", "health__pop_per_dentist"), grid.resolution = 10) %>%  pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, colorkey = TRUE, screen = list(z = -20, x = -60))


gridExtra::grid.arrange(p1, p2, p3, p4, p5, p6, p7, ncol = 4)

```


_Investigation of GAM_

```{r}
#plot(gam_fit$finalModel, shade = TRUE, shade.col = "#add8e6")

library(DALEX)

explainer_gam <- DALEX::explain(gam_fit, label="gam", data = test, y = test_outcome)
explainer_mars <- DALEX::explain(mars_fit, label= "mars", data = test, y = test_outcome)
explainer_pcr <- DALEX::explain(pcr_fit, label= "pcr", data = test, y = test_outcome)


mp_gam <- model_performance(explainer_gam)
mp_mars <- model_performance(explainer_mars)
mp_pcr <- model_performance(explainer_pcr)

plot(mp_gam, mp_mars, mp_pcr)

vi_gam <- variable_importance(explainer_gam, loss_function = loss_root_mean_square)
vi_mars <- variable_importance(explainer_mars, loss_function = loss_root_mean_square)
vi_pcr <- variable_importance(explainer_pcr, loss_function = loss_root_mean_square)

plot(vi_gam, vi_mars, vi_pcr)
```

Compared to MARS and PCR, GAM gave more weight to the factor variable metropolitan status and metropolitan adjacency.

MARS, GAM, and PCR, had similar distributions of residuals.

## Discussion
```{r include = FALSE}
cv_RMSE <- summary(res)$statistics$RMSE
gam_RMSE <- summary(res)$statistics$RMSE[5,]
```


GAM was our best-performing model. With GAM, we were able to achieve a cross-validated RMSE of median `r paste(round(gam_RMSE[3], 2))` and bootstrapped interquartile range of (`r paste(round(gam_RMSE[2], 2))`, `r paste(round(gam_RMSE[5], 2))`. GAM, and MARS, also performed well on the test data

However, simpler and more interpretable linear models were close in performance to the more flexible models.

\pagebreak
## Appendix

### Data prep

```{r, eval=F}
## Data import
predictors <- read_csv("./data/Training_values.csv") 
response <- read_csv("./data/Training_labels.csv") 


## Manipulation
data <- response %>% 
  full_join(predictors, by = "row_id") %>%
  separate(col = area__rucc, into = c('metro', 'population'), sep = ' - ') %>%
  rename(urban_influence = area__urban_influence,
         economic_typology = econ__economic_typology) %>%
  mutate(pure_population = fct_collapse(as.factor(population), 
                                        "more_than_1mil" = "Counties in metro areas of 1 million population or more",
                                        "250k_to_1mil" = "Counties in metro areas of 250,000 to 1 million population",
                                        "less_than_250k" = "Counties in metro areas of fewer than 250,000 population",
                                        "more_than_20k" = c("Urban population of 20,000 or more, adjacent to a metro area", 
                                                               "Urban population of 20,000 or more, not adjacent to a metro area"),
                                        "2500_to_20k" = c("Urban population of 2,500 to 19,999, adjacent to a metro area", 
                                                             "Urban population of 2,500 to 19,999, not adjacent to a metro area"),
                                        "less_than_2500" = c("Completely rural or less than 2,500 urban population, adjacent to a metro area", 
                                                        "Completely rural or less than 2,500 urban population, not adjacent to a metro area")),
         economic_typology = as.factor(recode(economic_typology,
                                              "Nonspecialized" = "Nonspecialized",
                                              "Manufacturing-dependent" = "Manufacturing",
                                              "Farm-dependent" = "Farming",
                                              "Federal/State government-dependent" = "Government",
                                              "Mining-dependent" = "Mining",
                                              "Recreation" = "Recreation")),
        metro = factor(metro, 
                       levels = c("Metro", "Nonmetro")),
        urban_influence = str_replace_all(urban_influence, " |/|-", "_"), # replace problematic characters
        urban_influence = str_replace_all(urban_influence, ",", ""), # replace problematic characters
        demo__pct_nonwhite = demo__pct_hispanic + demo__pct_asian + demo__pct_american_indian_or_alaskan_native + demo__pct_non_hispanic_african_american,
        urban_influence = fct_rev(urban_influence),
        metro_adjacency = fct_collapse(population, 
                                       metro = c("Counties in metro areas of 1 million population or more", 
                                                 "Counties in metro areas of 250,000 to 1 million population", 
                                                 "Counties in metro areas of fewer than 250,000 population"),
                                       adjacent = c("Urban population of 20,000 or more, adjacent to a metro area", 
                                                    "Urban population of 2,500 to 19,999, adjacent to a metro area", 
                                                    "Completely rural or less than 2,500 urban population, adjacent to a metro area"),
                                       nonadjacent = c("Urban population of 20,000 or more, not adjacent to a metro area", 
                                                       "Urban population of 2,500 to 19,999, not adjacent to a metro area", 
                                                       "Completely rural or less than 2,500 urban population, not adjacent to a metro area"))) %>% 
  dplyr::select(-demo__pct_hispanic, 
                -demo__pct_asian,
                -demo__pct_american_indian_or_alaskan_native, 
                -demo__pct_non_hispanic_african_american,
                -demo__pct_non_hispanic_white,
                -health__homicides_per_100k, # >90% missing
                -health__pct_excessive_drinking, # >90% missing
                -yr,
                -population,
                -row_id) 


```


Training and testing data split. Imputation on missing data.

```{r, eval=F}
## training/test data
set.seed(1)
train_ind <- sample(seq_len(nrow(data)), size = 2/3*nrow(data)) # select rows in 2:1 ratio 

train <- data[train_ind, ] # training dataset
test <- data[-train_ind, ] # testing dataset

# Imputation for missing values with caret, based on training data
training_preproc = caret::preProcess(train[,-1], 
                                     method = "knnImpute", # automatically centers and scales data
                                     pcaComp = 10,
                                     na.remove = TRUE,
                                     k = 5,
                                     knnSummary = mean,
                                     outcome = NULL,
                                     fudge = .2,
                                     numUnique = 3,
                                     verbose = TRUE)

# Impute training imputation on both training and testing datasets
train_imputed = predict(training_preproc, train)
test_imputed = predict(training_preproc, test)

#save files to Rdata: was not saving the factor structure in read from csv
saveRDS(train_imputed, file = './data/train_imputed.Rdata')
saveRDS(train_imputed, file = './data/test_imputed.Rdata')

```


*Linear Models*

Set up `caret` training control. We will use this for all models.

```{r}
set.seed(100)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
```


Stepwise regression:
```{r, eval=F}
set.seed(2)
step.fit = caret::train(x, y, 
                        method = 'glmStepAIC',
                        metric = "RMSE",
                        trControl = ctrl)
saveRDS(step.fit, "lm_step_imputed.rds")
```


Lasso:
```{r, eval=F}
set.seed(2)
lasso_fit <- caret::train(x, y,
                          method = "glmnet",
                          metric = "RMSE",
                          tuneGrid = expand.grid(alpha = 1,
                                                lambda = exp(seq(-2, 4, length = 200))),
                          trControl = ctrl)
plot(lasso_fit, xTrans = function(x) log(x)) #in correct range

saveRDS(lasso_fit, "lasso_imputed.rds")
```


Ridge:
```{r, eval=F}
set.seed(100)

ridge_fit <- caret::train(x, y,
                     method = "glmnet",
                     tuneGrid = expand.grid(alpha = 0, 
                                            lambda = exp(seq(-2, 10, length = 200))),
                    trControl = ctrl1)


plot(ridge_fit, xTrans = function(x) log(x)) #in correct range

best_lambda_ridge = ridge_fit$bestTune$lambda 

saveRDS(ridge_fit, "ridge.rds")
```


PCR:
```{r, eval=F}
set.seed(2)
pcr_fit <- caret::train(x, y,
                        method = "pcr",
                        trControl = ctrl,
                        metric = "RMSE",
                        tuneLength = 200)
saveRDS(pcr_fit, "pcr_imputed.rds")
```



*Non-linear models*


GAM:
```{r, eval=F}
set.seed(2)
gam_fit <- caret::train(x, y, 
                        method = "gam",
                        metric = 'RMSE',
                        tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE, FALSE)),
                        trControl = ctrl)
summary(gam_fit)
saveRDS(gam_fit, "gam_fit_imputed.rds")

```


MARS:
```{r, eval=F}
mars_grid <- expand.grid(degree = 1:3, # degree: 1 vs 2 vs 3, no interaction vs. interaction;
                         nprune = 10:40) # nprune is number of coef

set.seed(2)

mars_fit <- caret::train(x, y,
                         method = "earth",
                         tuneGrid = mars_grid,
                         trControl = ctrl)

saveRDS(mars_fit, "mars.rds")

#based on initial results, choose parsimonious version
mars_grid_refined <- expand.grid(degree = 2, nprune = 25:40) 

mars_fit_refined <- caret::train(x, y,
                                 method = "earth",
                                 tuneGrid = mars_grid_refined,
                                 trControl = ctrl)
saveRDS(mars_fit_refined, "mars2.rds")

```

